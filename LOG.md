# 100DayLearningLog


## Day 1
* Basics of Pandas and Numpy
* Creating and training the model
* Learnt and Implemented the basics of [Linear Regression](https://github.com/Aman9026/100DaysOfMachineLearning/tree/master/Regression/INFO.md)

## Day 2
* Learnt and Implemented more [Linear Regression](https://github.com/Aman9026/100DaysOfMachineLearning/tree/master/Regression/INFO.md)
* Created graph for visualization


## Day 3
* Learnt and Implemented prediction graphs
* Created graph for visualization

## Day 4
* Created a ML model and integrated it with a basic python program
* Created graph for visualization

## Day 5
* Learnt about [Multi-Linear Regression](https://github.com/Aman9026/100DaysOfMachineLearning/tree/master/Regression/INFO.md)
* Learnt about Feature selection
* Learnt about MAE, MSE and RMS

## Day 6
* Learnt more about Feature Selecton
* Learnt about Correlation
* Learnt more about [Multi-Linear Regression](https://github.com/Aman9026/100DaysOfMachineLearning/tree/master/Regression/INFO.md)

## Day 7
* Learnt more about the coefficient and feature selection
* Created a [Multi-Linear Regression](https://github.com/Aman9026/100DaysOfMachineLearning/tree/master/Regression/INFO.md)

## Day 8
* Learnt significance of negative Co-efficient 
* Learnt and Implemented Embedded method(co-efficiency and lesso method/L1 regularization), Label and One-Hot Encoding. 

## Day 9
* Learnt Dimensionality Reduction, Depth discussion on Wrapper Method, Feature Extraction, Principle Component Analysis, OLS method to find important features, Importance of P-Value and Adjusted R-Square, Backward Elimination. 
* Implemented categorical values in dummy variable.

## Day 10
* Learnt use of gretl software, Mathematical logic behind p-value, Null and Alternative Hypothesis, Sample Testing, Traditional, ML(sklearn) vs Modern ML(neural network).Brief overview of BigData.
* Implemented Facial Recognition


## Day 11
* Learnt how sklearn is using numpy.Tensor datatype.Tensorflow library along with Lazy and Eager Execution.
* Convertied Eager execution to Lazy execution using @tf.function (Decorator syntax).
* Used a python script for observing changes of loss and gradient descent continuously.
