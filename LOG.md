# 100DayLearningLog


## Day 1
* Basics of Pandas and Numpy
* Creating and training the model
* Learnt and Implemented the basics of [Linear Regression](https://github.com/Aman9026/100DaysOfMachineLearning/tree/master/Regression/INFO.md)

## Day 2
* Learnt and Implemented more [Linear Regression](https://github.com/Aman9026/100DaysOfMachineLearning/tree/master/Regression/INFO.md)
* Created graph for visualization


## Day 3
* Learnt and Implemented prediction graphs
* Created graph for visualization

## Day 4
* Created a ML model and integrated it with a basic python program
* Created graph for visualization

## Day 5
* Learnt about [Multi-Linear Regression](https://github.com/Aman9026/100DaysOfMachineLearning/tree/master/Regression/INFO.md)
* Learnt about Feature selection
* Learnt about MAE, MSE and RMS

## Day 6
* Learnt more about Feature Selecton
* Learnt about Correlation
* Learnt more about [Multi-Linear Regression](https://github.com/Aman9026/100DaysOfMachineLearning/tree/master/Regression/INFO.md)

## Day 7
* Learnt more about the coefficient and feature selection
* Created a [Multi-Linear Regression](https://github.com/Aman9026/100DaysOfMachineLearning/tree/master/Regression/INFO.md)

## Day 8

Learnt:
 Significance of negative Co-efficient. More discussion on Co-relation method. Depth discussion on Embedded method(co-efficiency and lesso method/L1 regularization).Label and One-Hot Encoding. Feature Engineering. Categorical Variables. Dummy Variables. Pandas DataFrame. Dummy variable Trap. Multi-co-linearity. Redundant Variables.
Implemented:
 Using SelectFromModel(Lasso(alpha=0.01)) creating lesso model and using .get_support observing features. Finding dummy variables using pandas(pd.get_dummies(state)).Row wise operation in DataFrame using iloc function. After lesso modelling finding the co-efficiency to see which features are important.
